## Метрики
Для оценки решений участников предлагается использовать **две метрики: генеративную и классификационную метрику**.

Качество ответов на вопросы с выбором варианта ответа (из предложенных вариантов) предлагается оценивать с помощью **классификационной метрики Accuracy** (доля правильных ответов), которая основывается на внутренней оценке уверенности модели в вариантах ответа на вопрос по видеозаписи. Участникам предлагается, в рамках вычисления данной метрики, рассчитать численные значение перплексии модели в ответ на входные варианты ответа на вопрос. Затем, на основе данных значений осуществить выбор наиболее вероятного, с точки зрения оцениваемой модели, варианта ответа. На выходе решение участника должно выдать номер выбранного варианта ответа. Финальным значением метрики будет доля правильно отвеченных вопросов (выбранный вариант ответа совпадает с правильным) относительно общего числа вопросов (Accuracy).

Качество ответов на вопросы без выбора варианта ответа (открытая генерация) или вопросы, направленные на описание видео, оценивается с помощью **генеративной метрики METEOR**. 

Финальный результат участника и распределение мест будет оцениваться в соответствии с **интегральной метрикой**. <br>

### Классификационная метрика

**Accuracy** — классификационная метрика для оценки качества ответов на вопросы с выбором ответа из данных вариантов. Она основывается на **внутренней оценке уверенности модели в каждом из ответов**. 
Участникам предлагается, в рамках вычисления данной метрики, рассчитать численные значения **перплексии модели** в ответ на входные варианты ответа на вопрос. Затем выбрать наиболее вероятный, с точки зрения вычисленных значений перплексии, вариант ответа из предложенных.
В качестве итогового ответа для расчета Accuracy участник должен передать только номер выбранного варианта ответа.

**Перплексия** в языковой модели — определяется как эскпонента от усредненной функции отрицательного правдоподобия (negative log-likelihood) последовательности токенов.

Таким образом, если мы имеем некоторую токенизированную последовательность X=(x0,x1,…,xt), тогда значение перплексии для последовательности X вычисляется как:

![image](https://latex.codecogs.com/svg.image?\large&space;\dpi{150}&space;PPL(X)=exp^{\frac{1}{t}\sum_{i}^{t}log&space;p_{\theta}(x_{i}|x_{<i})})

где ![image](https://latex.codecogs.com/svg.image?\large&space;\dpi{150}log&space;p_{\theta}(x_{i}|x_{<i})) - это правдоподобие i-ого токена при условии всех x<i токенов, в соотвествии с предсказаниями модели.

Кроме того, показатель перплексии - это ни что иное как экспонента кросс-энтропийного критерия качества между предсказаниями модели и целевыми ответами.

Классификационная метрика будет вычисляться по файлу acc_output.json и принимать значения от 0 до 1, где 0 – наихудшее значение, 1 – наилучшее.


### Генеративная метрика
Метрику оценки генерации ответов модели предлагается рассчитывать с применением **METEOR**.

**METEOR** – метрика, основанная на анализе n-грамм и ориентированная на использование статистической и точной оценки исходного текста. 
Данная метрика использует функции сопоставления синонимов вместе с точным соответствием слов. 

Алгоритм сначала проводит выравнивание текста между двумя предложениями – строкой эталонного перевода и строкой входного текста для оценивания. Затем используется несколько этапов установления соответствия между словами машинного перевода и эталонного перевода для сопоставления двух строк:
1. Точное установление соответствия — определяются строки, которые являются идентичными в эталонном и машинном переводе.
2. Установление соответствия основ — проводится стемминг (выделение основы слова), и определяются слова с одинаковым корнем в эталонном и машинном переводе.
3. Установление соответствия синонимов — определяются слова, которые являются синонимами.

Выравнивание — это множество соответствий между n-граммами. На соответствие налагается следующее ограничение: каждый n-грамм в предложении-кандидате должен соответствовать одному или ни одному n-грамму в эталонном предложении. Если есть два выравнивания с тем же количеством совпадений, то выбирается то, которое имеет наименьшее количество пересечений для совпадений. Этапы сравнения с эталонными переводами выполняются последовательно, и на каждом из них ко множеству соответствий добавляются только те n-граммы, которые не имели соответствия на предыдущих этапах. Как только будет пройден последний этап, окончательное значение точности (precision) n-грамм вычисляется по следующей формуле:


![image](https://latex.codecogs.com/svg.image?\text{P}=\frac{m}{w_t},)

где $m$ - количество n-грамм в машинном переводе, которые также были найдены в эталонном переводе, $w_t$ — количество n-грамм в машинном переводе. 

Значение полноты (recall) n-грамм (общий n-грамм для эталонных переводов) вычисляется по следующей формуле:

![image](https://latex.codecogs.com/svg.image?\text{R}=\frac{m}{w_r},)

где $w_r$ — количество n-грамм в эталонном переводе.

В результате METEOR рассчитывается как комбинация точности и полноты, используя формулу гармонического среднего, в которой вес полноты в 9 раз больше веса точности:

![image](https://latex.codecogs.com/svg.image?\text{METEOR}=\frac{10PR}{R&plus;9P}.)

Генеративная метрика будет вычисляться по файлу gen_output.json и принимать значения от 0 до 1, где 0 – наихудшее значение, 1 – наилучшее.

### Интегральная метрика

Метрики вычисляются по каждому типу вопросов и агрегируются с соответствующими весовыми коэффициентами.
Таким образом, интегральная метрика вычисляется по следующей формуле:

![image](https://latex.codecogs.com/svg.image?&space;w_{M}\times\sum_{j}^{J_{o}}METEOR_{j}&plus;w_{A}\times\sum_{i}^{J_{m}}Accuracy_{i})




где ![image](https://latex.codecogs.com/svg.image?J_{m})   и   ![image](https://latex.codecogs.com/svg.image?J_{o})  — число вопросов каждого типа, с выбором ответа (multiple-choice) и открытые (open-ended) соответственно;

![image](https://latex.codecogs.com/svg.image?METEOR_{j})   и    ![image](https://latex.codecogs.com/svg.image?Accuracy_{i}) — значения метрики METEOR и Accuracy, вычисленные для j-го и i-ого вопроса соответственно;

![image](https://latex.codecogs.com/svg.image?w_{M})   и   ![image](https://latex.codecogs.com/svg.image?w_{A}) — вес метрики METEOR и Accuracy, соответственно.
